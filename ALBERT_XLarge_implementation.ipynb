{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ALBERT_XLarge_implementation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOSRWJvcK+zYQF4+AQc+m8f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anitayadav3/EmotionRecognitionInConversation/blob/master/ALBERT_XLarge_implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kD0mFXy7R3wy",
        "outputId": "de0d2f19-52b9-442c-dae7-832e6c770455"
      },
      "source": [
        "!pip install tensorflow==1.15\r\n",
        "!pip install \"tensorflow_hub>=0.6.0\"\r\n",
        "!pip3 install tensorflow_text==1.15"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 27kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.19.5)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.12.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.3.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.10.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.12.4)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 46.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.3MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 55.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.32.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.36.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.15) (53.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.3.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.4.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=2863afaa40232efadaf16073a6a9b45dfc3395c70b69e5d682d7d3ed532b75ea\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, keras-applications, tensorflow-estimator, gast, tensorflow\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n",
            "Requirement already satisfied: tensorflow_hub>=0.6.0 in /usr/local/lib/python3.6/dist-packages (0.11.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub>=0.6.0) (3.12.4)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub>=0.6.0) (1.19.5)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow_hub>=0.6.0) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow_hub>=0.6.0) (53.0.0)\n",
            "Collecting tensorflow_text==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/61/9569353ce3efb8ee818d0d2e2f67afbb19e1e3a56eba3a93986e92949003/tensorflow_text-1.15.0-cp36-cp36m-manylinux1_x86_64.whl (9.1MB)\n",
            "\u001b[K     |████████████████████████████████| 9.1MB 9.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow<1.16,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_text==1.15) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (3.3.0)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.15.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (0.36.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.1.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.0.8)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (3.12.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.32.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.12.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (0.8.1)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (0.2.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.19.5)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (0.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (53.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (3.3.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (3.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (3.7.4.3)\n",
            "Installing collected packages: tensorflow-text\n",
            "Successfully installed tensorflow-text-1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhXSEZvoSTFW",
        "outputId": "37c28d08-a286-4be1-f84a-f83385dd05e1"
      },
      "source": [
        "import numpy as np # linear algebra\r\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\r\n",
        "import numpy as np\r\n",
        "import re\r\n",
        "import nltk\r\n",
        "from nltk.corpus import stopwords\r\n",
        "nltk.download('stopwords')\r\n",
        "nltk.download('punkt')\r\n",
        "from nltk.tokenize import word_tokenize\r\n",
        "import pandas as pd\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.layers import Dense, Input, GRU, Dropout\r\n",
        "from tensorflow.keras.optimizers import Adam\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\r\n",
        "import tensorflow_hub as hub\r\n",
        "import pickle\r\n",
        "from sklearn.metrics import f1_score\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "import string\r\n",
        "import requests"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "of3MxH4bSeiM",
        "outputId": "e2046804-4ff9-4afc-9c34-4233a7e9b613"
      },
      "source": [
        "!wget --quiet https://raw.githubusercontent.com/tensorflow/models/master/official/nlp/bert/tokenization.py\r\n",
        "!pip install sentencepiece\r\n",
        "import tokenization"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/67/e42bd1181472c95c8cda79305df848264f2a7f62740995a46945d9797b67/sentencepiece-0.1.95-cp36-cp36m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\r\u001b[K     |▎                               | 10kB 29.0MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 3.6MB/s eta 0:00:01\r\u001b[K     |▉                               | 30kB 5.2MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 6.7MB/s eta 0:00:01\r\u001b[K     |█▍                              | 51kB 8.1MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61kB 9.5MB/s eta 0:00:01\r\u001b[K     |██                              | 71kB 10.5MB/s eta 0:00:01\r\u001b[K     |██▏                             | 81kB 11.6MB/s eta 0:00:01\r\u001b[K     |██▌                             | 92kB 12.5MB/s eta 0:00:01\r\u001b[K     |██▊                             | 102kB 13.5MB/s eta 0:00:01\r\u001b[K     |███                             | 112kB 13.5MB/s eta 0:00:01\r\u001b[K     |███▎                            | 122kB 13.5MB/s eta 0:00:01\r\u001b[K     |███▌                            | 133kB 13.5MB/s eta 0:00:01\r\u001b[K     |███▉                            | 143kB 13.5MB/s eta 0:00:01\r\u001b[K     |████                            | 153kB 13.5MB/s eta 0:00:01\r\u001b[K     |████▍                           | 163kB 13.5MB/s eta 0:00:01\r\u001b[K     |████▋                           | 174kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████                           | 184kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 194kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 204kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 215kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████                          | 225kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 235kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 245kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 256kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████                         | 266kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 276kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 286kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████                        | 296kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 307kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 317kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 327kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████                       | 337kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 348kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 358kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 368kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████                      | 378kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 389kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 399kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████                     | 409kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 419kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 430kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 440kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████                    | 450kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 460kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 471kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 481kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 491kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 501kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 512kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 522kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 532kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 542kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 552kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 563kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 573kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 583kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 593kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████                | 604kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 614kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 624kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 634kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 645kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 655kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 665kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 675kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 686kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 696kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 706kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 716kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 727kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 737kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 747kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 757kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 768kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 778kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 788kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 798kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 808kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 819kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 829kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 839kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 849kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 860kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 870kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 880kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 890kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 901kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 911kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 921kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 931kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 942kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 952kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 962kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 972kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 983kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 993kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.0MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.0MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.0MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.0MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.0MB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1MB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.1MB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.1MB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.1MB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1MB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.1MB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.1MB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1MB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.1MB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.1MB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.2MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2MB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.2MB 13.5MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgpIFiqBSoOk"
      },
      "source": [
        "albert_module = hub.Module(\"https://tfhub.dev/google/albert_xlarge/1\",trainable=True)\r\n",
        "# albert_inputs = dict(input_ids=input_ids,input_mask=input_mask,segment_ids=segment_ids)\r\n",
        "# albert_outputs = albert_module(albert_inputs, signature=\"tokens\", as_dict=True)\r\n",
        "# pooled_output = albert_outputs[\"pooled_output\"]\r\n",
        "# sequence_output = albert_outputs[\"sequence_output\"]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZ7Ok2pVTCCk"
      },
      "source": [
        "def albert_encode(texts, tokenizer, max_len=512):\r\n",
        "    all_tokens = []\r\n",
        "    all_masks = []\r\n",
        "    all_segments = []\r\n",
        "    \r\n",
        "    for text in texts:\r\n",
        "        text = tokenizer.tokenize(text)\r\n",
        "            \r\n",
        "        text = text[:max_len-2]\r\n",
        "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\r\n",
        "        pad_len = max_len - len(input_sequence)\r\n",
        "        \r\n",
        "        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\r\n",
        "        tokens += [0] * pad_len\r\n",
        "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\r\n",
        "        segment_ids = [0] * max_len\r\n",
        "        \r\n",
        "        all_tokens.append(tokens)\r\n",
        "        all_masks.append(pad_masks)\r\n",
        "        all_segments.append(segment_ids)\r\n",
        "    \r\n",
        "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6VvpPT-TGGL"
      },
      "source": [
        "def build_model(bert_layer, max_len=512):\r\n",
        "    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\r\n",
        "    input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\r\n",
        "    segment_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\r\n",
        "\r\n",
        "    pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\r\n",
        "    clf_output = pooled_output\r\n",
        "    out = Dense(100, activation='relu')(clf_output)\r\n",
        "    out = Dense(100, activation='relu')(out)\r\n",
        "    out = Dense(6, activation='softmax')(out)\r\n",
        "    \r\n",
        "    model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\r\n",
        "    model.compile(Adam(lr=2e-6), loss='binary_crossentropy', metrics=['accuracy'])\r\n",
        "    \r\n",
        "    return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gc5OZqyHTPSO",
        "outputId": "a0de0123-212e-4a01-e505-d4a1f4274391",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_QZ-sxWTjsR"
      },
      "source": [
        "with open('/content/gdrive/My Drive/iemocap/train/sentences.pkl', 'rb') as f:\r\n",
        "    data = pickle.load(f)\r\n",
        "with open('/content/gdrive/My Drive/iemocap/train/labels.pkl', 'rb') as f:\r\n",
        "    labels = pickle.load(f)\r\n",
        "with open('/content/gdrive/My Drive/iemocap/test/sentences.pkl', 'rb') as f:\r\n",
        "    test_data = pickle.load(f)\r\n",
        "with open('/content/gdrive/My Drive/iemocap/test/labels.pkl', 'rb') as f:\r\n",
        "    test_labels = pickle.load(f)\r\n",
        "with open('/content/gdrive/MyDrive/iemocap/train/conversation_length.pkl', 'rb') as f:\r\n",
        "    train_convlen = pickle.load(f)\r\n",
        "with open('/content/gdrive/MyDrive/iemocap/test/conversation_length.pkl', 'rb') as f:\r\n",
        "    test_convlen = pickle.load(f)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afun2p8KTkXH"
      },
      "source": [
        "def preprocessing(data,labels):\r\n",
        "  processed_data=[]\r\n",
        "  processed_label=[]\r\n",
        "  for i in range(0,len(data)):\r\n",
        "    for j in range(0,len(data[i])):\r\n",
        "      intermediate_data=[]\r\n",
        "      intermediate_label=[]\r\n",
        "      for k in range(0,len(data[i][j])):\r\n",
        "        text=data[i][j][k]\r\n",
        "        if text != '<eos>'and text!='<pad>':\r\n",
        "          intermediate_data.append(text)\r\n",
        "      processed_data.append(intermediate_data)\r\n",
        "  for i in labels:\r\n",
        "    for j in i:\r\n",
        "      processed_label.append(j)\r\n",
        "  return processed_data,processed_label"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_B6e9ugToWq"
      },
      "source": [
        "processed_data,processed_label = preprocessing(data,labels)\r\n",
        "test_processed_data,test_processed_label = preprocessing(test_data,test_labels)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwIo8IX5TqPw"
      },
      "source": [
        "for i in range(0,len(processed_data)):\r\n",
        "  processed_data[i]= ' '.join(processed_data[i])\r\n",
        "for i in range(0,len(test_processed_data)):\r\n",
        "  test_processed_data[i]=' '.join(test_processed_data[i])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pa5Q4L3JTrJl"
      },
      "source": [
        "with open('/content/processed_data.pkl', 'rb') as f:\r\n",
        "    processed_data = pickle.load(f)\r\n",
        "with open('/content/processed_label.pkl', 'rb') as f:\r\n",
        "    processed_label = pickle.load(f)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpkIFZZ1WoBf",
        "outputId": "46f86720-af9c-4d2f-ce7b-5ca086cd9be3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        }
      },
      "source": [
        "import keras\r\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomRotation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras.layers.experimental.preprocessing'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-4c52b67c20bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     raise ImportError(\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;34m'Keras requires TensorFlow 2.2 or higher. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         'Install TensorFlow via `pip install tensorflow`')\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3o46nH1MT4AX",
        "outputId": "679ddab2-d241-4d41-f6d1-7fc7b4ebbb2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "processed_data=np.asarray(processed_data)\r\n",
        "test_processed_data=np.asarray(test_processed_data)\r\n",
        "Y=to_categorical(processed_label, num_classes=6)\r\n",
        "test_Y=to_categorical(test_processed_label, num_classes=6)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-e233db44c335>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprocessed_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest_processed_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_processed_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtest_Y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_processed_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'to_categorical' is not defined"
          ]
        }
      ]
    }
  ]
}